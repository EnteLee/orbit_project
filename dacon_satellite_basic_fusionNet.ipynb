{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 72
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2631,
     "status": "ok",
     "timestamp": 1588686925806,
     "user": {
      "displayName": "유영재",
      "photoUrl": "",
      "userId": "15071020987067673937"
     },
     "user_tz": -540
    },
    "id": "JoH_3CiLQvQg",
    "outputId": "1abf2b0d-307d-4c9b-ee2c-2ad2137ec084"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\statsmodels\\tools\\_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
      "  import pandas.util.testing as tm\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pylab as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "import tensorflow as tf\n",
    "import os\n",
    "from os.path import join\n",
    "import random\n",
    "import lightgbm as lgb\n",
    "import time\n",
    "from tensorflow.python.framework import ops\n",
    "from tensorflow.python.ops import math_ops\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.keras.layers import Dense, Conv2D, Dropout, Conv2DTranspose, MaxPooling2D, BatchNormalization\n",
    "from tensorflow.keras.layers import Activation, concatenate, Input, GlobalAveragePooling2D\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.callbacks import TensorBoard, ModelCheckpoint, ReduceLROnPlateau, EarlyStopping\n",
    "import warnings\n",
    " \n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon May 11 13:53:36 2020       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 432.00       Driver Version: 432.00       CUDA Version: 10.1     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name            TCC/WDDM | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  TITAN X (Pascal)   WDDM  | 00000000:01:00.0  On |                  N/A |\n",
      "| 29%   51C    P0    74W / 250W |   1183MiB / 12288MiB |      1%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                       GPU Memory |\n",
      "|  GPU       PID   Type   Process name                             Usage      |\n",
      "|=============================================================================|\n",
      "|    0       520    C+G   ...osoft.LockApp_cw5n1h2txyewy\\LockApp.exe N/A      |\n",
      "|    0       956    C+G   ...Local\\Microsoft\\Teams\\current\\Teams.exe N/A      |\n",
      "|    0      2824    C+G   ...6.102.0_x64__kzf8qxf38zg5c\\SkypeApp.exe N/A      |\n",
      "|    0      4020    C+G   ...1.88.0_x64__8wekyb3d8bbwe\\YourPhone.exe N/A      |\n",
      "|    0      4772    C+G   ...x64__8wekyb3d8bbwe\\Microsoft.Photos.exe N/A      |\n",
      "|    0      5808    C+G   ...cal\\Programs\\Microsoft VS Code\\Code.exe N/A      |\n",
      "|    0      6696    C+G   ...hell.Experiences.TextInput.InputApp.exe N/A      |\n",
      "|    0      7064    C+G   ...ta\\Local\\Postman\\app-7.23.0\\Postman.exe N/A      |\n",
      "|    0      7532    C+G   ...t_cw5n1h2txyewy\\ShellExperienceHost.exe N/A      |\n",
      "|    0      8444    C+G   C:\\ProgramData\\Anaconda3\\pythonw.exe       N/A      |\n",
      "|    0      9584    C+G   ...dows.Cortana_cw5n1h2txyewy\\SearchUI.exe N/A      |\n",
      "|    0     11020    C+G   ...Local\\Microsoft\\Teams\\current\\Teams.exe N/A      |\n",
      "|    0     13484    C+G   C:\\Windows\\explorer.exe                    N/A      |\n",
      "|    0     14964    C+G   ...6)\\Google\\Chrome\\Application\\chrome.exe N/A      |\n",
      "|    0     17016    C+G   Insufficient Permissions                   N/A      |\n",
      "|    0     19200    C+G   ...0.0.0_x64__8wekyb3d8bbwe\\Calculator.exe N/A      |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 11673321790902535330\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 10074609419\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 3430381292429849271\n",
      "physical_device_desc: \"device: 0, name: TITAN X (Pascal), pci bus id: 0000:01:00.0, compute capability: 6.1\"\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 230
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 10390,
     "status": "ok",
     "timestamp": 1588686937648,
     "user": {
      "displayName": "유영재",
      "photoUrl": "",
      "userId": "15071020987067673937"
     },
     "user_tz": -540
    },
    "id": "2_M479deR4-Z",
    "outputId": "f81d9b0b-ec4e-4594-ca2f-6c158c6f1b0b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_layer shape: (None, 40, 40, 14)\n",
      "img_layer shape: (None, 40, 40, 9)\n",
      "ext_layer shape: (None, 40, 40, 5)\n",
      "img_layer shape: (None, 40, 40, 9)\n",
      "conv1 shape: (None, 40, 40, 32)\n",
      "maxpool 1 shape: (None, 20, 20, 32)\n",
      "conv2 shape: (None, 20, 20, 64)\n",
      "maxpool 2 shape: (None, 10, 10, 64)\n",
      "convm shape: (None, 10, 10, 128)\n",
      "upconv2 shape: (None, 20, 20, 64)\n",
      "upconv1 shape: (None, 40, 40, 32)\n",
      "output shape: (None, 40, 40, 1)\n"
     ]
    }
   ],
   "source": [
    "def conv_block_3(img_layer, start_neurons):\n",
    "    conv1 = Conv2D(start_neurons, (3, 3), activation=\"relu\", padding=\"same\")(img_layer)\n",
    "    conv1 = BatchNormalization()(conv1)\n",
    "    conv2 = Conv2D(start_neurons, (3, 3), activation=\"relu\", padding=\"same\")(conv1)\n",
    "    conv2 = BatchNormalization()(conv2)\n",
    "    conv3 = Conv2D(start_neurons, (3, 3), activation=\"relu\", padding=\"same\")(conv2)\n",
    "    conv3 = BatchNormalization()(conv3)\n",
    "\n",
    "    return conv3\n",
    "\n",
    "def conv_residual(img_layer, start_neurons):\n",
    "    conv1 = Conv2D(start_neurons, (3, 3), activation=\"relu\", padding=\"same\")(img_layer)\n",
    "    conv1 = BatchNormalization()(conv1)\n",
    "    conv2 = conv_block_3(conv1, start_neurons)\n",
    "    conv2 = BatchNormalization()(conv2)\n",
    "    conv3 = Conv2D(start_neurons, (3, 3), activation=\"relu\", padding=\"same\")(conv1 + conv2)\n",
    "    conv3 = BatchNormalization()(conv3)\n",
    "\n",
    "    return conv3\n",
    "\n",
    "def model_v1(input_layer, start_neurons):\n",
    "    # divide raw feature to image feature and external feature\n",
    "    img_layer = input_layer[:,:,:,:9]\n",
    "    ext_layer = input_layer[:,:,:,9:]\n",
    "    print('input_layer shape:', input_layer.shape)\n",
    "    print('img_layer shape:', img_layer.shape)\n",
    "    print('ext_layer shape:', ext_layer.shape)\n",
    "\n",
    "    # 40 x 40 -> 20 x 20\n",
    "    print('img_layer shape:', img_layer.shape)\n",
    "    conv1 = conv_residual(img_layer, start_neurons * 1)\n",
    "    print('conv1 shape:', conv1.shape)\n",
    "    pool1 = MaxPooling2D((2, 2))(conv1)\n",
    "    print('maxpool 1 shape:', pool1.shape)\n",
    "    pool1 = Dropout(0.25)(pool1)\n",
    "\n",
    "    # 20 x 20 -> 10 x 10\n",
    "    conv2 = conv_residual(pool1, start_neurons * 2)\n",
    "    print('conv2 shape:', conv2.shape)\n",
    "    pool2 = MaxPooling2D((2, 2))(conv2)\n",
    "    print('maxpool 2 shape:', pool2.shape)\n",
    "    pool2 = Dropout(0.25)(pool2)\n",
    "\n",
    "    # 10 x 10 \n",
    "    convm = conv_residual(pool2, start_neurons * 4)\n",
    "    print('convm shape:', convm.shape)\n",
    "\n",
    "    # 10 x 10 -> 20 x 20\n",
    "    deconv2 = Conv2DTranspose(start_neurons * 2, (3, 3), strides=(2, 2), padding=\"same\")(convm)\n",
    "    uconv2 = concatenate([deconv2, conv2])\n",
    "    uconv2 = conv_residual(uconv2, start_neurons * 2)\n",
    "    print('upconv2 shape:', uconv2.shape)\n",
    "    uconv2 = Dropout(0.25)(uconv2)\n",
    "\n",
    "    # 20 x 20 -> 40 x 40\n",
    "    deconv1 = Conv2DTranspose(start_neurons * 1, (3, 3), strides=(2, 2), padding=\"same\")(uconv2)\n",
    "    uconv1 = concatenate([deconv1, conv1])\n",
    "    uconv1 = conv_residual(uconv1, start_neurons * 1)\n",
    "    print('upconv1 shape:', uconv1.shape)\n",
    "    uconv1 = Dropout(0.25)(uconv1)\n",
    "    output_layer = Conv2D(1, (1,1), padding=\"same\", activation='relu')(uconv1)\n",
    "    print('output shape:', output_layer.shape)\n",
    "    \n",
    "    return output_layer\n",
    "\n",
    "input_layer = Input((40, 40, 14))\n",
    "output_layer = model_v1(input_layer, 32)\n",
    "model = Model(input_layer, output_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ko4QW3K3oUWn"
   },
   "outputs": [],
   "source": [
    "# training_set.ftr 파일에 맞는 input 생성 코드\n",
    "def input_generator_ftr_train():\n",
    "    # train feather 파일 로드 및 orbit, subset 조합 생성\n",
    "    TRAIN_FILE = './training_set.ftr'\n",
    "    train = pd.read_feather(TRAIN_FILE)\n",
    "    file_cnt = 0\n",
    "    temp_info = train[['orbit', 'subset']].drop_duplicates()\n",
    "    orbit = temp_info['orbit'].tolist()\n",
    "    subset = temp_info['subset'].tolist()\n",
    "    del temp_info\n",
    "    size = len(orbit)\n",
    "  \n",
    "  # 하나의 이미지 데이터에 해당하는 것만 3차원 변환 및 피처/라벨 생성\n",
    "    for i in range(size):\n",
    "        one_img = train.loc[(train['orbit'] == orbit[i]) & (train['subset'] == subset[i])].sort_values('pixel')\n",
    "        one_img = np.array(one_img.drop(['orbit', 'subset', 'pixel'], axis=1)).reshape([40,40,15])\n",
    "        target = one_img[:,:,-1].reshape(40,40,1)\n",
    "        cutoff_labels = np.where(target < 0,0, target)\n",
    "        feature = one_img[:,:,:-1]\n",
    "        # if (cutoff_labels > 0).sum() < 50: continue\n",
    "        yield(feature, cutoff_labels)\n",
    "        file_cnt += 1\n",
    "\n",
    "train_dataset = tf.data.Dataset.from_generator(input_generator_ftr_train, (tf.float32, tf.float32),\n",
    "                                               (tf.TensorShape([40,40,14]),tf.TensorShape([40,40,1])))\n",
    "train_dataset = train_dataset.batch(1024).prefetch(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vzpTEpcgTm5H"
   },
   "outputs": [],
   "source": [
    "# custom loss fuction (maeOverFscore)\n",
    "def recall_m(y_true, y_pred):\n",
    "    true_positives = tf.dtypes.cast(K.sum(K.round(K.clip(y_true * y_pred, 0, 1))), dtype=tf.float32)\n",
    "    possible_positives = tf.dtypes.cast(K.sum(K.round(K.clip(y_true, 0, 1))), dtype=tf.float32)\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    return recall\n",
    "\n",
    "def precision_m(y_true, y_pred):\n",
    "    true_positives = tf.dtypes.cast(K.sum(K.round(K.clip(y_true * y_pred, 0, 1))), dtype=tf.float32)\n",
    "    predicted_positives = tf.dtypes.cast(K.sum(K.round(K.clip(y_pred, 0, 1))), dtype=tf.float32)\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    return precision\n",
    "\n",
    "def f1_m(y_true, y_pred):\n",
    "    idx_one_true = tf.greater_equal(y_true, 0.1)\n",
    "    y_true = tf.where(idx_one_true == True, 1, 0)\n",
    "    idx_one_pred = tf.greater_equal(y_pred, 0.1)\n",
    "    y_pred = tf.where(idx_one_pred == True, 1, 0)\n",
    "    precision = precision_m(y_true, y_pred)\n",
    "    recall = recall_m(y_true, y_pred)\n",
    "    return 2*((precision*recall)/(precision+recall+K.epsilon()))\n",
    "\n",
    "def mae(y_true, y_pred):\n",
    "    over_threshold = tf.greater_equal(y_true, 0.1)\n",
    "    return K.mean(math_ops.abs(y_pred - y_true), axis=-1)\n",
    "\n",
    "def maeOverFscore(y_true, y_pred):\n",
    "    y_true = tf.reshape(y_true, [-1])\n",
    "    y_pred = tf.reshape(y_pred, [-1])\n",
    "    return mae(y_true, y_pred) / f1_m(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 573,
     "status": "ok",
     "timestamp": 1588688877490,
     "user": {
      "displayName": "유영재",
      "photoUrl": "",
      "userId": "15071020987067673937"
     },
     "user_tz": -540
    },
    "id": "4Bngn0xdD5jo",
    "outputId": "8f4a0cba-588a-49a1-c6ab-299521f54919"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of samples seen.\n"
     ]
    }
   ],
   "source": [
    "ROOT_DIR_PATH = os.getcwd()\n",
    "WEIGHT_DIR = join(ROOT_DIR_PATH,'./checkpoint/')\n",
    "LOG_DIR = join(ROOT_DIR_PATH, 'log')\n",
    "# logging = TensorBoard(log_dir=LOG_DIR)\n",
    "\n",
    "tb_hist = TensorBoard(log_dir=LOG_DIR, histogram_freq=0, write_graph=True, write_images=True)\n",
    "checkpoint = ModelCheckpoint(WEIGHT_DIR + 'v01_ep{epoch:02d}-loss{loss:.5f}.ckpt', mode='min',\n",
    "                             monitor='loss', save_weights_only=True, period=1, verbose=1)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='loss', factor=0.1, patience=1, verbose=1)\n",
    "early_stopping = EarlyStopping(monitor='loss', min_delta=0, patience=3, verbose=1)\n",
    "\n",
    "callbacks = [tb_hist, checkpoint, reduce_lr, early_stopping]\n",
    "adam = tf.keras.optimizers.Adam(learning_rate=1.0e-07)\n",
    "model.compile(loss=maeOverFscore, optimizer=adam, metrics=[mae])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FY4e8ssgppAx"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Documents\\not_for_git\\orbit_project\\./checkpoint/v01_ep04-loss0.86484.ckpt\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x26639949940>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 이전에 훈련한 weight를 이어서 훈련할 경우 실행\n",
    "latest = tf.train.latest_checkpoint(WEIGHT_DIR)\n",
    "print(latest)\n",
    "model.load_weights(latest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 23820862,
     "status": "error",
     "timestamp": 1588686678043,
     "user": {
      "displayName": "유영재",
      "photoUrl": "",
      "userId": "15071020987067673937"
     },
     "user_tz": -540
    },
    "id": "UD3FM3FpWzM2",
    "outputId": "455d2121-b301-4027-915e-29ab4ad349f3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/14\n",
      "     24/Unknown - 461s 461s/step - loss: 0.9510 - mae: 0.141 - 896s 448s/step - loss: 0.9845 - mae: 0.147 - 1323s 441s/step - loss: 0.9489 - mae: 0.14 - 1751s 438s/step - loss: 0.9915 - mae: 0.14 - 2190s 438s/step - loss: 0.9517 - mae: 0.14 - 2624s 437s/step - loss: 0.9403 - mae: 0.14 - 3074s 439s/step - loss: 0.9563 - mae: 0.14 - 3506s 438s/step - loss: 0.9390 - mae: 0.14 - 3946s 438s/step - loss: 0.9173 - mae: 0.15 - 4366s 437s/step - loss: 0.9015 - mae: 0.15 - 4787s 435s/step - loss: 0.8905 - mae: 0.16 - 5214s 435s/step - loss: 0.8877 - mae: 0.16 - 5667s 436s/step - loss: 0.8803 - mae: 0.17 - 6091s 435s/step - loss: 0.8704 - mae: 0.17 - 6521s 435s/step - loss: 0.8643 - mae: 0.18 - 6965s 435s/step - loss: 0.8623 - mae: 0.18 - 7407s 436s/step - loss: 0.8587 - mae: 0.18 - 7867s 437s/step - loss: 0.8556 - mae: 0.19 - 8326s 438s/step - loss: 0.8526 - mae: 0.19 - 8764s 438s/step - loss: 0.8494 - mae: 0.19 - 9205s 438s/step - loss: 0.8479 - mae: 0.19 - 9633s 438s/step - loss: 0.8472 - mae: 0.19 - 10066s 438s/step - loss: 0.8494 - mae: 0.192 - 10500s 437s/step - loss: 0.8491 - mae: 0.1920"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "epochs = 14\n",
    "model_history = model.fit(train_dataset, epochs = epochs, verbose=1,\n",
    "                          callbacks=callbacks)\n",
    "print('{}epoch 파일 학습 시간:'.format(epochs), round((time.time()-start)/60, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kzZbiR6VszdJ"
   },
   "source": [
    "# Cross Validation 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gh7AcnkOd2m6"
   },
   "outputs": [],
   "source": [
    "# cv,ftr 파일에 맞는 input 생성 코드\n",
    "def input_generator_ftr_cv():\n",
    "    # cv feather 파일 로드 및 orbit, subset 조합 생성\n",
    "    CV_FILE = './ftr_data/cv.ftr'\n",
    "    cv = pd.read_feather(CV_FILE)\n",
    "    file_cnt = 0\n",
    "    temp_info = cv[['orbit', 'subset']].drop_duplicates()\n",
    "    orbit = temp_info['orbit'].tolist()\n",
    "    subset = temp_info['subset'].tolist()\n",
    "    del temp_info\n",
    "    size = len(orbit)\n",
    "  \n",
    "  # 하나의 이미지 데이터에 해당하는 것만 3차원 변환 및 피처/라벨 생성\n",
    "    for i in range(size):\n",
    "        one_img = cv.loc[(cv['orbit'] == orbit[i]) & (cv['subset'] == subset[i])].sort_values('pixel')\n",
    "        one_img = np.array(one_img.drop(['orbit', 'subset', 'pixel'], axis=1)).reshape([40,40,15])\n",
    "        target = one_img[:,:,-1].reshape(40,40,1)\n",
    "        cutoff_labels = np.where(target < 0,0, target)\n",
    "        feature = one_img[:,:,:-1]\n",
    "        # if (cutoff_labels > 0).sum() < 50: continue\n",
    "        yield(feature, cutoff_labels)\n",
    "        file_cnt += 1\n",
    "\n",
    "cv_dataset = tf.data.Dataset.from_generator(input_generator_ftr_cv, (tf.float32, tf.float32),\n",
    "                                            (tf.TensorShape([40,40,14]),tf.TensorShape([40,40,1])))\n",
    "cv_dataset = cv_dataset.batch(64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4u46zXCJexLi"
   },
   "outputs": [],
   "source": [
    "WEIGHT_DIR = './checkpoint/'\n",
    "LOG_DIR = './log/'\n",
    "latest = tf.train.latest_checkpoint(WEIGHT_DIR)\n",
    "print(latest)\n",
    "model.load_weights(latest)\n",
    "logging = TensorBoard(log_dir=LOG_DIR)\n",
    "result = model.evaluate(cv_dataset)\n",
    "dict(zip(model.metrics_names, result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "H5Z-kEWflHxP"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "c-VKz9Rstf1a"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BBfOOLtXW8HC"
   },
   "outputs": [],
   "source": [
    "# fusionNet과 external feature 까지 고려하는 모델 (미완성)\n",
    "def conv_block_3(img_layer, start_neurons):\n",
    "    conv1 = Conv2D(start_neurons, (3, 3), activation=\"relu\", padding=\"same\")(img_layer)\n",
    "    conv1 = BatchNormalization()(conv1)\n",
    "    conv2 = Conv2D(start_neurons, (3, 3), activation=\"relu\", padding=\"same\")(conv1)\n",
    "    conv2 = BatchNormalization()(conv2)\n",
    "    conv3 = Conv2D(start_neurons, (3, 3), activation=\"relu\", padding=\"same\")(conv2)\n",
    "    conv3 = BatchNormalization()(conv3)\n",
    "\n",
    "    return conv3\n",
    "\n",
    "def conv_residual(img_layer, start_neurons):\n",
    "    conv1 = Conv2D(start_neurons, (3, 3), activation=\"relu\", padding=\"same\")(img_layer)\n",
    "    conv1 = BatchNormalization()(conv1)\n",
    "    conv2 = conv_block_3(conv1, start_neurons)\n",
    "    conv2 = BatchNormalization()(conv2)\n",
    "    conv3 = Conv2D(start_neurons, (3, 3), activation=\"relu\", padding=\"same\")(conv1 + conv2)\n",
    "    conv3 = BatchNormalization()(conv3)\n",
    "\n",
    "    return conv3\n",
    "\n",
    "def model_v2(input_layer, start_neurons, ext_neurons):\n",
    "    # divide raw feature to image feature and external feature\n",
    "    img_layer = input_layer[:,:,:,:9]\n",
    "    ext_layer = input_layer[:,:,:,9:]\n",
    "    print('input_layer shape:', input_layer.shape)\n",
    "    print('img_layer shape:', img_layer.shape)\n",
    "    print('ext_layer shape:', ext_layer.shape)\n",
    "\n",
    "    # 40 x 40 -> 20 x 20\n",
    "    print('img_layer shape:', img_layer.shape)\n",
    "    conv1 = conv_residual(img_layer, start_neurons * 1)\n",
    "    print('conv1 shape:', conv1.shape)\n",
    "    pool1 = MaxPooling2D((2, 2))(conv1)\n",
    "    print('maxpool 1 shape:', pool1.shape)\n",
    "    pool1 = Dropout(0.25)(pool1)\n",
    "\n",
    "    # 20 x 20 -> 10 x 10\n",
    "    conv2 = conv_residual(pool1, start_neurons * 2)\n",
    "    print('conv2 shape:', conv2.shape)\n",
    "    pool2 = MaxPooling2D((2, 2))(conv2)\n",
    "    print('maxpool 2 shape:', pool2.shape)\n",
    "    pool2 = Dropout(0.25)(pool2)\n",
    "\n",
    "    # 10 x 10 \n",
    "    convm = conv_residual(pool2, start_neurons * 4)\n",
    "    print('convm shape:', convm.shape)\n",
    "\n",
    "    # 10 x 10 -> 20 x 20\n",
    "    deconv2 = Conv2DTranspose(start_neurons * 2, (3, 3), strides=(2, 2), padding=\"same\")(convm)\n",
    "    uconv2 = concatenate([deconv2, conv2])\n",
    "    uconv2 = conv_residual(uconv2, start_neurons * 2)\n",
    "    print('upconv2 shape:', uconv2.shape)\n",
    "    uconv2 = Dropout(0.25)(uconv2)\n",
    "\n",
    "    # 20 x 20 -> 40 x 40\n",
    "    deconv1 = Conv2DTranspose(start_neurons * 1, (3, 3), strides=(2, 2), padding=\"same\")(uconv2)\n",
    "    uconv1 = concatenate([deconv1, conv1])\n",
    "    uconv1 = conv_residual(uconv1, start_neurons * 1)\n",
    "    print('upconv1 shape:', uconv1.shape)\n",
    "    uconv1 = Dropout(0.25)(uconv1)\n",
    "    output_layer = Conv2D(1, (1,1), padding=\"same\", activation='relu')(uconv1)\n",
    "    print('output shape:', output_layer.shape)\n",
    "\n",
    "    # process the external feature\n",
    "    ext_output = Conv2D(1, (1,1), padding=\"same\", activation='relu')(ext_layer)\n",
    "    ext_output = BatchNormalization()(ext_output)\n",
    "    ext_output = Dropout(0.25)(ext_output)\n",
    "    ext_output = Conv2D(1, (1,1), padding=\"same\", activation='relu')(ext_layer)\n",
    "    ext_output = BatchNormalization()(ext_output)\n",
    "\n",
    "    output_layer = concatenate(output_layer, ext_output)\n",
    "    \n",
    "    return output_layer\n",
    "\n",
    "input_layer = Input((40, 40, 14))\n",
    "output_layer = model_v1(input_layer, 32)\n",
    "model = Model(input_layer, output_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XZVBG1eWtjHC"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyNg+wLDqpZfuAQhFHxu0NvT",
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "dacon_satellite_basic_fusionNet.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
